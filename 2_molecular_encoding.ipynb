{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Molecular encoding\n",
    "\n",
    "In the last notebook we used the RDKit set of molecular descriptors to derive a numeric vector per molecule. Then we used some \"classical\" ML algotithms to develop a model predictive of LogP.\n",
    "\n",
    "The RDKit descriptor is only one of several. In this notebook we will look at various other descriptors available via the deepchem package (as its a nice API), and compare their predictive performance on this LogP problem. Then we move to a more challenging task, predicting biological activity against HIV1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "import random\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from rdkit import RDLogger\n",
    "from rdkit.Chem import AllChem\n",
    "import deepchem as dc\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key descriptors\n",
    "\n",
    "- rdkit descriptors: various cheap to calculate statistics and models. Such as number of H-bond acceptor/donors, molweight, SLogP\n",
    "\n",
    "- extended connectivity fingerprint (ecfp): This appraoch takes the set of molecules, and identifies the set of distinct functional groups containing n atoms (not including H or ions). i.e. if n is 3 then C=O-OH is legitimate, if n = 4 then CC=O-OH is a legitimate group. Each distinct group up to the mth most prevalent is then identified in molecules, and each molecule given a numeric vector of length m, where m is 1 if group x is present, of 0 if abscent.\n",
    "\n",
    "- MACCS: \n",
    "\n",
    "- mordred: Modred can be thought of as a richly extended variant of the RDKit descriptors containing many more descriptor implementations from various publications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define helper functions to help calculate vectors in parallel\n",
    "def smiles_2_rdkitDescr(smiles):\n",
    "    featurizer = dc.feat.RDKitDescriptors()\n",
    "    return(featurizer(smiles).flatten())\n",
    "\n",
    "def smiles_2_ecfp3(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol,3,nBits=1024,useFeatures=True)\n",
    "    arr = np.zeros((1,), dtype=np.int8)\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    return(arr)\n",
    "\n",
    "def smiles_2_ecfp4(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol,4,nBits=1024,useFeatures=True)\n",
    "    arr = np.zeros((1,), dtype=np.int8)\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    return(arr)\n",
    "\n",
    "def smiles_2_MACCS(smiles):\n",
    "    featurizer = dc.feat.MACCSKeysFingerprint()\n",
    "    return(featurizer(smiles).flatten())\n",
    "\n",
    "def smiles_2_mordredDescr(smiles):\n",
    "    featurizer = dc.feat.MordredDescriptors(ignore_3D=False)\n",
    "    return(featurizer(smiles).flatten())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we generate the vector of vectors for each type of descriptor\n",
    "df = pd.read_table('lib/data/1_data.tsv')\n",
    "y = df['Standard Value']\n",
    "\n",
    "# rdkit descriptors - 208 total\n",
    "with Pool(processes=os.cpu_count()) as p:\n",
    "    x_rdkit = np.stack(p.map(smiles_2_rdkitDescr, df.Smiles.values))\n",
    "\n",
    "# Extended fingerprint\n",
    "with Pool(processes=os.cpu_count()) as p:\n",
    "    x_ecfp3 = np.stack(p.map(smiles_2_ecfp3, df.Smiles.values))\n",
    "\n",
    "with Pool(processes=os.cpu_count()) as p:\n",
    "    x_ecfp4 = np.stack(p.map(smiles_2_ecfp4, df.Smiles.values))\n",
    "\n",
    "# MACCS\n",
    "with Pool(processes=os.cpu_count()) as p:\n",
    "    x_MACCS = np.stack(p.map(smiles_2_MACCS, df.Smiles.values))\n",
    "\n",
    "# Mordred - save this as its a long compute\n",
    "with Pool(processes=os.cpu_count()) as p:\n",
    "    x_mordred = np.stack(p.map(smiles_2_mordredDescr, df.Smiles.values))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have a set of vectors per molecule, which is best? Well we need to write some code to test this.\n",
    "For each descriptor let's build the same RF based model we did in notebook 1 with the same data, then we can compare like for like with only 1 independant variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature - algorithm - RMSE - r2\n",
      "x_rdkit RF 0.3572 0.765705\n",
      "x_ecfp3 RF 0.729181 0.521714\n",
      "x_ecfp4 RF 0.604619 0.603417\n",
      "x_MACCS RF 0.368397 0.75836\n",
      "x_mordred RF 0.169895 0.888562\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# define a dict of ML algorithms\n",
    "dict_algorithm = {\n",
    "    \"RF\": RandomForestRegressor()\n",
    "}\n",
    "\n",
    "# define a dict of molvectors\n",
    "dict_feats = {\n",
    "    'x_rdkit': x_rdkit,\n",
    "    'x_ecfp3': x_ecfp3,\n",
    "    'x_ecfp4': x_ecfp4,\n",
    "    'x_MACCS': x_MACCS,\n",
    "    'x_mordred': x_mordred,\n",
    "}\n",
    "\n",
    "print('feature - algorithm - RMSE - r2')\n",
    "\n",
    "# for each molvector type\n",
    "for f, f_df in dict_feats.items():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        f_df,\n",
    "        y,\n",
    "        test_size=0.3,\n",
    "        random_state=123)\n",
    "    # for each algorithm\n",
    "    for m, model_instantiation in dict_algorithm.items():\n",
    "        model_instantiation.fit(x_train, y_train)\n",
    "        test_preds = model_instantiation.predict(x_test)\n",
    "        col1 = f\n",
    "        col2 = m\n",
    "\n",
    "        # predictive metrics\n",
    "        col3 = mean_squared_error(y_test, test_preds)\n",
    "        col4 = r2_score(y_test, test_preds)\n",
    "        \n",
    "        newrow = pd.DataFrame( [[col1, col2, col3, col4]] ,columns=['feat', 'model', 'RMSE', 'r2']) \n",
    "        print(newrow.to_string(index=False, header=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stop and think\n",
    "\n",
    "hmm so it looks like the RDKit descriptors are still good, but the modred descriptors are now optimal, makes sense it's essentially a richly extended set. A problem with this approach is that any given split especially with a small dataset like this can really impact the predictive performance. A  more rigorous test would be to run several test:train splits for each feature type and keep track of the mean perormance metrics. This is a good defailt approach to use.\n",
    "\n",
    "\n",
    "Below is the same code as above, but now the performance metrics are the mean from 10 random draws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature - algorithm - RMSE - r2\n",
      "x_rdkit RF 0.334428 0.85645\n",
      "x_ecfp3 RF 0.740151 0.621331\n",
      "x_ecfp4 RF 0.988282 0.488716\n",
      "x_MACCS RF 0.761469 0.681918\n",
      "x_mordred RF 0.463945 0.817753\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import random\n",
    "\n",
    "# define a dict of ML algorithms\n",
    "dict_algorithm = {\n",
    "    \"RF\": RandomForestRegressor()\n",
    "}\n",
    "\n",
    "# define a dict of molvectors\n",
    "dict_feats = {\n",
    "    'x_rdkit': x_rdkit,\n",
    "    'x_ecfp3': x_ecfp3,\n",
    "    'x_ecfp4': x_ecfp4,\n",
    "    'x_MACCS': x_MACCS,\n",
    "    'x_mordred': x_mordred,\n",
    "}\n",
    "\n",
    "print('feature - algorithm - RMSE - r2')\n",
    "\n",
    "resample_num = 5\n",
    "\n",
    "# for each molvector type\n",
    "for f, f_df in dict_feats.items():\n",
    "\n",
    "    # for each algorithm\n",
    "    for m, model_instantiation in dict_algorithm.items():\n",
    "\n",
    "        #traack metrics\n",
    "        rmse_total = 0\n",
    "        r2_total = 0\n",
    "\n",
    "        for rep in range(resample_num):\n",
    "            # each resmaple produces a novel dataset and model\n",
    "            x_train, x_test, y_train, y_test = train_test_split(\n",
    "                f_df,\n",
    "                y,\n",
    "                test_size=0.3,\n",
    "                random_state=random.randint(1,999))\n",
    "            model_instantiation.fit(x_train, y_train)\n",
    "\n",
    "            # tot up metrics\n",
    "            test_preds = model_instantiation.predict(x_test)\n",
    "            col1 = f\n",
    "            col2 = m\n",
    "            rmse_total = rmse_total + mean_squared_error(y_test, test_preds)\n",
    "            r2_total = r2_total + r2_score(y_test, test_preds)\n",
    "        \n",
    "        # get mean summary stats\n",
    "        mean_rmse = rmse_total / resample_num\n",
    "        mean_r2 = r2_total / resample_num\n",
    "\n",
    "        newrow = pd.DataFrame( [[col1, col2, mean_rmse, mean_r2]] ,columns=['feat', 'model', 'RMSE', 'r2']) \n",
    "        print(newrow.to_string(index=False, header=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "okay so rdkit is still very good, actually the top... that's not what we expect maybe this example is too simple.\n",
    "\n",
    "What happens if we move from this toy LogP example to something biologically complex like predicting inhibition of HIV protease? Here the inclusion of several LogP predictors within the descript might not be such an advantage....  \n",
    "\n",
    "A Ki value is like an IC50 but is normalised for the protein concentraion in the assay, which often varies across labs.\n",
    "\n",
    "This is a more of a real world test:\n",
    "\n",
    "The dataset we will use will be from CHemBL again, this time its 3700 molecules (only 400) will be used here, where each molecule has a Ki in nM range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>pKi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C#CCN1C(=O)N(CC#C)[C@H](Cc2ccccc2)[C@@H]2OC(C)...</td>\n",
       "      <td>1.342423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C#CCN1C(=O)N(CC#C)[C@H](Cc2ccccc2)[C@H](O)[C@@...</td>\n",
       "      <td>1.342423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C/C(=C\\C(=O)N(C)[C@@H](Cc1ccccc1)[C@H](O)CN(Cc...</td>\n",
       "      <td>1.720490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C/C(=N/O)c1cccc(CN2C(=O)N(Cc3cccc(/C(C)=N/O)c3...</td>\n",
       "      <td>-1.744727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C/C(=N/O)c1cccc(CN2[C@H](COc3ccccc3)[C@H](O)[C...</td>\n",
       "      <td>0.531479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2524</th>\n",
       "      <td>O[C@H]1C[C@H](Cc2ccccc2)[C@H](O)[C@@H](Cc2cccc...</td>\n",
       "      <td>6.301030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2525</th>\n",
       "      <td>S=C(NCCOc1nc2cc(Cl)ccc2n2cccc12)Nc1ccc(Br)cn1</td>\n",
       "      <td>1.845098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2526</th>\n",
       "      <td>[N-]=[N+]=N[C@@H](Cc1ccccc1)[C@@H]1[C@@H](O)[C...</td>\n",
       "      <td>2.518514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2527</th>\n",
       "      <td>[N-]=[N+]=Nc1ccc(S(=O)(=O)Nc2cccc(C(c3c(O)oc4c...</td>\n",
       "      <td>0.414973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2528</th>\n",
       "      <td>[O-][S+]1C[C@](CO)(Cc2ccccc2)C(O)[C@@](CO)(Cc2...</td>\n",
       "      <td>4.113943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2529 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 smiles       pKi\n",
       "0     C#CCN1C(=O)N(CC#C)[C@H](Cc2ccccc2)[C@@H]2OC(C)...  1.342423\n",
       "1     C#CCN1C(=O)N(CC#C)[C@H](Cc2ccccc2)[C@H](O)[C@@...  1.342423\n",
       "2     C/C(=C\\C(=O)N(C)[C@@H](Cc1ccccc1)[C@H](O)CN(Cc...  1.720490\n",
       "3     C/C(=N/O)c1cccc(CN2C(=O)N(Cc3cccc(/C(C)=N/O)c3... -1.744727\n",
       "4     C/C(=N/O)c1cccc(CN2[C@H](COc3ccccc3)[C@H](O)[C...  0.531479\n",
       "...                                                 ...       ...\n",
       "2524  O[C@H]1C[C@H](Cc2ccccc2)[C@H](O)[C@@H](Cc2cccc...  6.301030\n",
       "2525      S=C(NCCOc1nc2cc(Cl)ccc2n2cccc12)Nc1ccc(Br)cn1  1.845098\n",
       "2526  [N-]=[N+]=N[C@@H](Cc1ccccc1)[C@@H]1[C@@H](O)[C...  2.518514\n",
       "2527  [N-]=[N+]=Nc1ccc(S(=O)(=O)Nc2cccc(C(c3c(O)oc4c...  0.414973\n",
       "2528  [O-][S+]1C[C@](CO)(Cc2ccccc2)C(O)[C@@](CO)(Cc2...  4.113943\n",
       "\n",
       "[2529 rows x 2 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data cleaning - not all chembl entries are created equal\n",
    "df = pd.read_table('lib/data/2_hiv_protease.tsv')\n",
    "\n",
    "# some entries are missing label values\n",
    "df = df[df['Standard Value'] > 0]\n",
    "\n",
    "# there are duplicate values, let's get the mean Ki per smiles\n",
    "df = pd.DataFrame( df.groupby(['Smiles'])['Standard Value'].mean() )\n",
    "\n",
    "# now the Ki values are very diverse, let's take the log10 transform\n",
    "data = {'smiles': df['Standard Value'].index,\n",
    "        'pKi': np.log10(df['Standard Value'].values)}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscar/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/oscar/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/oscar/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/oscar/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "# Now we generate the vector of vectors for each type of descriptor\n",
    "df = df[0:500]\n",
    "y = df['pKi']\n",
    "\n",
    "# rdkit descriptors - 208 total\n",
    "with Pool(processes=os.cpu_count()) as p:\n",
    "    x_rdkit = np.stack(p.map(smiles_2_rdkitDescr, df.smiles.values))\n",
    "\n",
    "# Extended fingerprint\n",
    "with Pool(processes=os.cpu_count()) as p:\n",
    "    x_ecfp3 = np.stack(p.map(smiles_2_ecfp3, df.smiles.values))\n",
    "\n",
    "with Pool(processes=os.cpu_count()) as p:\n",
    "    x_ecfp4 = np.stack(p.map(smiles_2_ecfp4, df.smiles.values))\n",
    "\n",
    "# MACCS\n",
    "with Pool(processes=os.cpu_count()) as p:\n",
    "    x_MACCS = np.stack(p.map(smiles_2_MACCS, df.smiles.values))\n",
    "\n",
    "# Mordred - save this as its a long compute\n",
    "with Pool(processes=os.cpu_count()) as p:\n",
    "    x_mordred = np.stack(p.map(smiles_2_mordredDescr, df.smiles.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature - algorithm - RMSE - r2\n",
      "x_rdkit RF 4.265442 0.427186\n",
      "x_ecfp3 RF 4.973149 0.426824\n",
      "x_ecfp4 RF 5.07824 0.42575\n",
      "x_MACCS RF 4.370579 0.479738\n",
      "x_mordred RF 4.262423 0.461935\n"
     ]
    }
   ],
   "source": [
    "# now let's apply our previous code to this problem\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import random\n",
    "\n",
    "# define a dict of ML algorithms\n",
    "dict_algorithm = {\n",
    "    \"RF\": RandomForestRegressor()\n",
    "}\n",
    "\n",
    "# define a dict of molvectors\n",
    "dict_feats = {\n",
    "    'x_rdkit': x_rdkit,\n",
    "    'x_ecfp3': x_ecfp3,\n",
    "    'x_ecfp4': x_ecfp4,\n",
    "    'x_MACCS': x_MACCS,\n",
    "    'x_mordred': x_mordred,\n",
    "}\n",
    "\n",
    "print('feature - algorithm - RMSE - r2')\n",
    "\n",
    "resample_num = 5\n",
    "\n",
    "# for each molvector type\n",
    "for f, f_df in dict_feats.items():\n",
    "\n",
    "    # for each algorithm\n",
    "    for m, model_instantiation in dict_algorithm.items():\n",
    "\n",
    "        #traack metrics\n",
    "        rmse_total = 0\n",
    "        r2_total = 0\n",
    "\n",
    "        for rep in range(resample_num):\n",
    "            # each resmaple produces a novel dataset and model\n",
    "            x_train, x_test, y_train, y_test = train_test_split(\n",
    "                f_df,\n",
    "                y,\n",
    "                test_size=0.3,\n",
    "                random_state=random.randint(1,999))\n",
    "            model_instantiation.fit(x_train, y_train)\n",
    "\n",
    "            # tot up metrics\n",
    "            test_preds = model_instantiation.predict(x_test)\n",
    "            col1 = f\n",
    "            col2 = m\n",
    "            rmse_total = rmse_total + mean_squared_error(y_test, test_preds)\n",
    "            r2_total = r2_total + r2_score(y_test, test_preds)\n",
    "        \n",
    "        # get mean summary stats\n",
    "        mean_rmse = rmse_total / resample_num\n",
    "        mean_r2 = r2_total / resample_num\n",
    "\n",
    "        newrow = pd.DataFrame( [[col1, col2, mean_rmse, mean_r2]] ,columns=['feat', 'model', 'RMSE', 'r2']) \n",
    "        print(newrow.to_string(index=False, header=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# washup - what did we learn\n",
    "\n",
    "Here in this problem we see that the rdkit descriptors ave been outcompeted by MACCS and modred. the mean errors are quite close but the r2 values are circa 20-25% greater with these two descriptors. This is more in line broadly with the literature.\n",
    "\n",
    "This is a problem that is highly complex compared to the prevous LogP example. we have 500 datapoints not 100, the compounds are of a greater diversity in general, and the problem is much more difficult. we have no good basic algorithms that can just give you a fairly good score of how good a HIV1-protease inhibitor a molecule will be, you have to experimentally measure this, sorry.\n",
    "\n",
    "Here then we see that rdkit is outcompetedd, the 208 numebrs it uses are not containing as sufficient detail as the far richer MACCS and mordred descriptors. Althought ecfp curiously weren't that performant here, unable to outcompete rdkit despite their richer descriptioons of molecules. Then again thir downfall is their resolution, being binary rather than floating points.\n",
    "\n",
    "The take home is that it's worth trying a few appraches to encoding your molecules into vectors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
