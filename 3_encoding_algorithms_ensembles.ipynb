{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Many encodings, many algorithms, and ensembles.\n",
    "\n",
    "\n",
    "In the last example we used HIV1 protease inhibition data to compare the QSAR modelling performance when using different descriptors, why did we not iterate through ML algorithms? Let's do that here!\n",
    "\n",
    "You will then learn that using the pooled output of many models can often outperform any given model, this has the term \" an ensemble model\"."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 22:32:16.248334: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-06 22:32:18.862747: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-06 22:32:18.872668: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-06 22:32:30.552626: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Skipped loading some PyTorch models, missing a dependency. No module named 'torch'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch'\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'torch'\n",
      "Skipped loading some Jax models, missing a dependency. jax requires jaxlib to be installed. See https://github.com/google/jax#installation for installation instructions.\n"
     ]
    }
   ],
   "source": [
    "# general\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "import random\n",
    "\n",
    "# data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# cheminformatics\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "import deepchem as dc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning as previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>pKi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C#CCN1C(=O)N(CC#C)[C@H](Cc2ccccc2)[C@@H]2OC(C)...</td>\n",
       "      <td>1.342423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C#CCN1C(=O)N(CC#C)[C@H](Cc2ccccc2)[C@H](O)[C@@...</td>\n",
       "      <td>1.342423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C/C(=C\\C(=O)N(C)[C@@H](Cc1ccccc1)[C@H](O)CN(Cc...</td>\n",
       "      <td>1.720490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C/C(=N/O)c1cccc(CN2C(=O)N(Cc3cccc(/C(C)=N/O)c3...</td>\n",
       "      <td>-1.744727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C/C(=N/O)c1cccc(CN2[C@H](COc3ccccc3)[C@H](O)[C...</td>\n",
       "      <td>0.531479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2524</th>\n",
       "      <td>O[C@H]1C[C@H](Cc2ccccc2)[C@H](O)[C@@H](Cc2cccc...</td>\n",
       "      <td>6.301030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2525</th>\n",
       "      <td>S=C(NCCOc1nc2cc(Cl)ccc2n2cccc12)Nc1ccc(Br)cn1</td>\n",
       "      <td>1.845098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2526</th>\n",
       "      <td>[N-]=[N+]=N[C@@H](Cc1ccccc1)[C@@H]1[C@@H](O)[C...</td>\n",
       "      <td>2.518514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2527</th>\n",
       "      <td>[N-]=[N+]=Nc1ccc(S(=O)(=O)Nc2cccc(C(c3c(O)oc4c...</td>\n",
       "      <td>0.414973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2528</th>\n",
       "      <td>[O-][S+]1C[C@](CO)(Cc2ccccc2)C(O)[C@@](CO)(Cc2...</td>\n",
       "      <td>4.113943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2529 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 smiles       pKi\n",
       "0     C#CCN1C(=O)N(CC#C)[C@H](Cc2ccccc2)[C@@H]2OC(C)...  1.342423\n",
       "1     C#CCN1C(=O)N(CC#C)[C@H](Cc2ccccc2)[C@H](O)[C@@...  1.342423\n",
       "2     C/C(=C\\C(=O)N(C)[C@@H](Cc1ccccc1)[C@H](O)CN(Cc...  1.720490\n",
       "3     C/C(=N/O)c1cccc(CN2C(=O)N(Cc3cccc(/C(C)=N/O)c3... -1.744727\n",
       "4     C/C(=N/O)c1cccc(CN2[C@H](COc3ccccc3)[C@H](O)[C...  0.531479\n",
       "...                                                 ...       ...\n",
       "2524  O[C@H]1C[C@H](Cc2ccccc2)[C@H](O)[C@@H](Cc2cccc...  6.301030\n",
       "2525      S=C(NCCOc1nc2cc(Cl)ccc2n2cccc12)Nc1ccc(Br)cn1  1.845098\n",
       "2526  [N-]=[N+]=N[C@@H](Cc1ccccc1)[C@@H]1[C@@H](O)[C...  2.518514\n",
       "2527  [N-]=[N+]=Nc1ccc(S(=O)(=O)Nc2cccc(C(c3c(O)oc4c...  0.414973\n",
       "2528  [O-][S+]1C[C@](CO)(Cc2ccccc2)C(O)[C@@](CO)(Cc2...  4.113943\n",
       "\n",
       "[2529 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table('lib/data/2_hiv_protease.tsv')\n",
    "# some entries are missing label values\n",
    "df = df[df['Standard Value'] > 0]\n",
    "# there are duplicate values, let's get the mean Ki per smiles\n",
    "df = pd.DataFrame( df.groupby(['Smiles'])['Standard Value'].mean() )\n",
    "# now the Ki values are very diverse, let's take the log10 transform\n",
    "data = {'smiles': df['Standard Value'].index,\n",
    "        'pKi': np.log10(df['Standard Value'].values)}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define helper functions to help calculate vectors in parallel\n",
    "def smiles_2_rdkitDescr(smiles):\n",
    "    featurizer = dc.feat.RDKitDescriptors()\n",
    "    return(featurizer(smiles).flatten())\n",
    "\n",
    "def smiles_2_ecfp3(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol,3,nBits=1024,useFeatures=True)\n",
    "    arr = np.zeros((1,), dtype=np.int8)\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    return(arr)\n",
    "\n",
    "def smiles_2_ecfp4(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol,4,nBits=1024,useFeatures=True)\n",
    "    arr = np.zeros((1,), dtype=np.int8)\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    return(arr)\n",
    "\n",
    "def smiles_2_MACCS(smiles):\n",
    "    featurizer = dc.feat.MACCSKeysFingerprint()\n",
    "    return(featurizer(smiles).flatten())\n",
    "\n",
    "def smiles_2_mordredDescr(smiles):\n",
    "    featurizer = dc.feat.MordredDescriptors(ignore_3D=False)\n",
    "    return(featurizer(smiles).flatten())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we generate the vector of vectors for each type of descriptor\n",
    "df = df[0:200]\n",
    "y = df['pKi']\n",
    "\n",
    "# rdkit descriptors - 208 total\n",
    "with Pool(processes=os.cpu_count()) as p:\n",
    "    x_rdkit = np.stack(p.map(smiles_2_rdkitDescr, df.smiles.values))\n",
    "\n",
    "# Extended fingerprint\n",
    "with Pool(processes=os.cpu_count()) as p:\n",
    "    x_ecfp3 = np.stack(p.map(smiles_2_ecfp3, df.smiles.values))\n",
    "\n",
    "with Pool(processes=os.cpu_count()) as p:\n",
    "    x_ecfp4 = np.stack(p.map(smiles_2_ecfp4, df.smiles.values))\n",
    "\n",
    "# MACCS\n",
    "with Pool(processes=os.cpu_count()) as p:\n",
    "    x_MACCS = np.stack(p.map(smiles_2_MACCS, df.smiles.values))\n",
    "\n",
    "# Mordred - commented out to save time\n",
    "#with Pool(processes=os.cpu_count()) as p:\n",
    "#    x_mordred = np.stack(p.map(smiles_2_mordredDescr, df.Smiles.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature - algorithm - RMSE - r2\n",
      "x_rdkit LR 9.227669e+19 -1.135705e+19\n",
      "x_rdkit KNN 8.119523 -0.087871\n",
      "x_rdkit DT 8.778026 -0.699454\n",
      "x_rdkit RF 5.685718 0.19222\n",
      "x_rdkit xgb3 6.503069 0.000019\n",
      "x_rdkit xgb4 7.019775 0.152754\n",
      "x_ecfp3 LR 2.955073e+27 -3.895561e+26\n",
      "x_ecfp3 KNN 4.745328 0.425525\n",
      "x_ecfp3 DT 6.523491 0.233176\n",
      "x_ecfp3 RF 4.658947 0.276264\n",
      "x_ecfp3 xgb3 5.980744 0.024374\n",
      "x_ecfp3 xgb4 5.185611 0.365605\n",
      "x_ecfp4 LR 3.008078e+27 -4.928348e+26\n",
      "x_ecfp4 KNN 4.132746 0.419916\n",
      "x_ecfp4 DT 7.740574 0.016389\n",
      "x_ecfp4 RF 4.960041 0.29256\n",
      "x_ecfp4 xgb3 6.209366 0.124537\n",
      "x_ecfp4 xgb4 5.068801 0.286116\n",
      "x_MACCS LR 1.841422e+25 -3.307634e+24\n",
      "x_MACCS KNN 5.63692 0.22788\n",
      "x_MACCS DT 9.493749 -0.205244\n",
      "x_MACCS RF 5.660772 0.244222\n",
      "x_MACCS xgb3 7.104456 0.080607\n",
      "x_MACCS xgb4 6.139033 0.209061\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "dict_algorithm = {\n",
    "    \"LR\": LinearRegression(),\n",
    "    \"KNN\": KNeighborsRegressor(),\n",
    "    \"DT\": DecisionTreeRegressor(max_depth=8),\n",
    "    \"RF\": RandomForestRegressor(),\n",
    "    \"xgb3\": xgb.XGBRegressor(n_estimators=200, max_depth=3),\n",
    "    \"xgb4\": xgb.XGBRFRegressor(n_estimators=200, max_depth=4),\n",
    "}\n",
    "\n",
    "dict_feats = {\n",
    "    'x_rdkit': x_rdkit,\n",
    "    'x_ecfp3': x_ecfp3,\n",
    "    'x_ecfp4': x_ecfp4,\n",
    "    'x_MACCS': x_MACCS,\n",
    "    #'x_mordred': x_mordred,    # commented out to save time\n",
    "}\n",
    "\n",
    "print('feature - algorithm - RMSE - r2')\n",
    "\n",
    "resample_num = 10\n",
    "\n",
    "# for each molvector type\n",
    "for f, f_df in dict_feats.items():\n",
    "\n",
    "    # for each algorithm\n",
    "    for m, model_instantiation in dict_algorithm.items():\n",
    "\n",
    "        #traack metrics\n",
    "        rmse_total = 0\n",
    "        r2_total = 0\n",
    "\n",
    "        for rep in range(resample_num):\n",
    "            \n",
    "            # each resmaple produces a novel dataset and model\n",
    "            x_train, x_test, y_train, y_test = train_test_split(\n",
    "                f_df,\n",
    "                y,\n",
    "                test_size=0.3,\n",
    "                random_state=random.randint(1,999))\n",
    "            model_instantiation.fit(x_train, y_train)\n",
    "\n",
    "            # tot up metrics\n",
    "            test_preds = model_instantiation.predict(x_test)\n",
    "            col1 = f\n",
    "            col2 = m\n",
    "            rmse_total = rmse_total + mean_squared_error(y_test, test_preds)\n",
    "            r2_total = r2_total + r2_score(y_test, test_preds)\n",
    "        \n",
    "        # get mean summary stats\n",
    "        mean_rmse = rmse_total / resample_num\n",
    "        mean_r2 = r2_total / resample_num\n",
    "\n",
    "        newrow = pd.DataFrame( [[col1, col2, mean_rmse, mean_r2]] ,columns=['feat', 'model', 'RMSE', 'r2']) \n",
    "        print(newrow.to_string(index=False, header=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So what did we learn?\n",
    "\n",
    "Here we took a problem, predicting the activity of HIV1 protease inhibitors. And using a set of classic ML QSAR models, tried to find the optimal mix of encoding and algorithm for a QSAR model.\n",
    "\n",
    "In this example the stochastic nature of the test:train split between different runs means each of us may have a different best model. I actually found KNN with ecfp4 the best, this may be as the data has a clumpy chemical space, with groups of active frameworks, and less active frameworks, but more on visualising that another time.   \n",
    "\n",
    "What happens if you increase the data size from 200 to 500, or 1000? does the best algorithm always stay the same?\n",
    "\n",
    "\n",
    "\n",
    "Now this is fairly comprehensive as far as classicML goes, but we can do a little better. There's one final concept to introduce that will / should improve our model, and that's combining models!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The endgame of classicML, the ensemble model\n",
    "\n",
    "Ensemble tree models, expand on decison trees. Rather thatn rely one \"well\" trained tree, they rely on many sub-optimal tree's then collate the output. Think of this as a medical problem, rather than taking one consultants opinion you instead take the average opinion of a diverse pool of junior doctors. Now why  stop your analogy there? If we asked for the opinions of many junior doctors across many hospitals, and totted dup their votes we could (should?) achieve better predictive power. This is what ensemble models (as in a model of models) try to do, Let's build one here!\n",
    "\n",
    "Now what we will do, it take the best performing models from above, re-run them, but collate their outputs.\n",
    "Let's use the xgb4 algorthm, and sum over all the different descriptors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RMSE - r2\n",
      "4.478775 0.49514\n",
      "3.93618 0.501792\n",
      "2.570388 0.607279\n",
      "4.560828 0.51086\n",
      "4.98882 0.376435\n"
     ]
    }
   ],
   "source": [
    "dict_algorithm = {\n",
    "    \"KNN\": KNeighborsRegressor(),\n",
    "}\n",
    "\n",
    "dict_feats = {\n",
    "    'x_rdkit': x_rdkit,\n",
    "    'x_ecfp3': x_ecfp3,\n",
    "    'x_ecfp4': x_ecfp4,\n",
    "    'x_MACCS': x_MACCS,\n",
    "    #'x_mordred': x_mordred,\n",
    "}\n",
    "\n",
    "print(' RMSE - r2')\n",
    "\n",
    "resample_num = 5\n",
    "\n",
    "for rep in range(resample_num):\n",
    "    i = 0\n",
    "\n",
    "    #traack metrics\n",
    "    rmse_total = 0\n",
    "    r2_total = 0\n",
    "\n",
    "    r_state = random.randint(1,999)\n",
    "         \n",
    "    # for each molvector type\n",
    "    for f, f_df in dict_feats.items():\n",
    "\n",
    "        # each resmaple produces a novel dataset and model\n",
    "        x_train, x_test, y_train, y_test = train_test_split(\n",
    "            f_df,\n",
    "            y,\n",
    "            test_size=0.3,\n",
    "            random_state=r_state)\n",
    "\n",
    "        # for each algorithm\n",
    "        for m, model_instantiation in dict_algorithm.items():\n",
    "\n",
    "            # get the sum of prediction value per test point\n",
    "            model_instantiation.fit(x_train, y_train)\n",
    "            if i == 0:\n",
    "                test_preds = model_instantiation.predict(x_test)\n",
    "            else:\n",
    "                test_preds = test_preds + model_instantiation.predict(x_test)\n",
    "            i = i+1\n",
    "        \n",
    "    # now get the mean predicted value per test datapoint\n",
    "    test_preds = test_preds / len(dict_feats)\n",
    "\n",
    "    rmse_total = rmse_total + mean_squared_error(y_test, test_preds)\n",
    "    r2_total = r2_total + r2_score(y_test, test_preds)\n",
    "        \n",
    "    # get mean summary stats\n",
    "    mean_rmse = rmse_total\n",
    "    mean_r2 = r2_total \n",
    "\n",
    "    newrow = pd.DataFrame( [[mean_rmse, mean_r2]] ,columns=['RMSE', 'r2']) \n",
    "    print(newrow.to_string(index=False, header=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there we have it, you can see that ensemble models, where we take the pooled output from many different models, is (or normally should be) an improvement on any given model. \n",
    "\n",
    "\n",
    "Try tinkering with the above code block, can you find the best combination?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
